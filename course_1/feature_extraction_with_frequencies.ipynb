{
 "cells": [
  {
   "source": [
    "This notebook aims at refreshing the concepts learned during Feature Extraction section in the course"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "| Postive Tweets                      |                             \n",
    "|-------------------------------------|                                      \n",
    "| I am happy because I am learning NLP|                            \n",
    "| I am happy                          |\n",
    "\n",
    "\n",
    "\n",
    "|------------------------------------|                                      \n",
    "\n",
    "\n",
    "\n",
    "| Negative Tweets                 |\n",
    "|---------------------------------| \n",
    "|I am sad, I am not learning NLP  |\n",
    "| I am sad                        |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Since we already have a list of already separated classes (positve and negative classes) of Tweets, we can now create a Vocabulary of Tweets. To achieve this, we need to collect all the unique words in the Tweets. We will also have to ignore pucntuation marks as well."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Vocabulary\n",
    "To build a vocabulary using the entire corpus we need to get all the unique words in the corpus. \n",
    "\n",
    "|  word  |\n",
    "|--------|\n",
    "|    I   |\n",
    "|   am   |\n",
    "| happy  |\n",
    "| because|\n",
    "|learning|\n",
    "| sad    |\n",
    "| not    |\n",
    "| NLP    |\n",
    "\n",
    "Notice that the words present in the above never repeat themselves. They are all unique words from the corus of tweets provided. The vocabulary is of length 8, because there are 8 unique words present in the corpus provided. Also, observe that the \",\" has been ignored because obviously this is not a word. \n",
    "\n",
    "The next cell creates the vocabulary using code\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "vocabulary: {'happy', 'sad', 'learning', 'not', 'am', 'because', 'I', 'NLP'}\n\nThe vocabulary is of length 8\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "positive_tweets = [\"I am happy because I am learning NLP\", \"I am happy\"]\n",
    "negative_tweets = [\"I am sad, I am not learning NLP\", \"I am sad\"]\n",
    "\n",
    "# Build a Vocabulary from the positive and negative tweets\n",
    "positive_tweets_vocab = ' '.join(positive_tweets)\n",
    "positive_tweets_vocab = re.sub(\",\", '', positive_tweets_vocab)\n",
    "positive_tweets_vocab = positive_tweets_vocab.split()\n",
    "\n",
    "# Build Negative tweets vocabulary\n",
    "negative_tweets_vocab = ' '.join(negative_tweets)\n",
    "negative_tweets_vocab = re.sub(\",\", '', negative_tweets_vocab)\n",
    "negative_tweets_vocab = negative_tweets_vocab.split()\n",
    "\n",
    "# Build a vocabulary containing both negative and positve classes\n",
    "vocab = negative_tweets_vocab + positive_tweets_vocab\n",
    "vocab = set(vocab)\n",
    "\n",
    "print(f'vocabulary: {vocab}\\n')\n",
    "print(f'The vocabulary is of length {len(vocab)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}